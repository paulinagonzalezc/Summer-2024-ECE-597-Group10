# Individual Participation

| Name             | Component                              | Contribution                                                                          |
| ---------------- | -------------------------------------- | ------------------------------------------------------------------------------------- |
| Paulina Gonzalez | ML Technique 2: SVM                    | Added cross-validation, implemented learning curve of training and cross-validation to check for overfitting. Also, added regularization c parameter to reduce overfitting and change code to use new dataset. |
| Jheel Shah       | Data Preprocessing                     | Initial Dataset Examination; Coordinating Preprocessing Start Points with teammates; TF-IDF vectorization and model training;Bag of Words vectorization and model training using the new updated training, validation and testing datasets; Provided teammates with the updated code for further implementation of ML models|
| Jharna Kumari    | Data Augumentation                     | Uvic dataset and Kaggle Normal Email dataset Augment. Collaborate with teammate to work on the same on colab. Downsample normal emails dataset. Split data into training, validation and test sets before feature extraction. Explore about PCA for dimensionality reduction. Removed Stopwords from the dataset in the cleaning process. Supplied training, validation and testing datasets to teammates resulting in increased accuracy. Implemented PCA but that led to decreased accuracy for ML models. Explore how to calculate correct number of principal components. |
| Bilel Matmti     | ML Technique 1: Logistic Regression    | Study existing research on email-based phishing detection, exploring the dataset to understand its structure and typical features found in emails, researching how Logistic Regression works and how to implement it, setting up logistic regression base code on jupyter notebook, constant improvements to our model (created multiple versions of our code & used multiple versions of our preprocessed dataset to obtain the best results possible), feature engineering, constantly analyzing and comparing results of our performance metrics used in logistic regression, implementing optimizations to improve our model, working with Zixin to implement cross-validation, constant reporting of our results in README file for logistic regression that is systemically organized & updated as progression occurs.       |       
| Adel Agha        | ML Technique 3: Random Forest          | Random Forest Classifier Research, Optimization and tuning parameters(Depth and Nestimators) for best performance. Attempting and developed different feature extraction techniques like OneHot and TF-IDF Vectorization, body text and misspelled word count. Applied Hypertuning parameters using RandomizedSearchCV to Validation and Test Data. Attempted another Hyperparameter tuning function RandomizedSearchCV, but execution kept on crashing. Tried useful arguments/functions for imbalance dataset challenge such class_weight={0: 1, 1: 2}, giving the spam detection twice importance when predicting. Continuuos exploration of TFIDF vectorizer functions like ngram, a method for tokenizing text for better performance. Working with balncing the model for reducing overfitting and underfitting. Multi-Classifier System will be attempted.                        |
| Zixin Li         | ML Technique 1: Logistic Regression    | Logistic Regression Research, Logistic Regression Optimization, Logistic Regression Cross Validation                                                          |
| Summer Liu       | ML Technique 2: SVM                    | Added cross-validation, compared the accuracy of two feature extraction methods.  Added roc curve graph and learning curves.|                    
| Birva Patel      | ML Technique 3: Random Forest          | Random Forest: Optimized and developed the Random Forest classifier using Scikit-Learn. Researched the algorithm and resolved ParserError issues with CSV files. Managed data preprocessing and incomplete file uploads. Developed hyperparameter tuning code, evaluated performance, and managed computational resources on Google Colab. Researched BERT for its potential applications.|                         
